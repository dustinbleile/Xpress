{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Call',\n",
       " 'GroupedMatrixTable',\n",
       " 'GroupedTable',\n",
       " 'HailType',\n",
       " 'Interval',\n",
       " 'Locus',\n",
       " 'MatrixTable',\n",
       " 'Pedigree',\n",
       " 'ReferenceGenome',\n",
       " 'Struct',\n",
       " 'Table',\n",
       " 'Trio',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__pip_version__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_compare',\n",
       " '_get_flags',\n",
       " '_locus_windows_per_contig',\n",
       " '_nd',\n",
       " '_set_flags',\n",
       " '_showstr',\n",
       " '_sort_by',\n",
       " '_values_similar',\n",
       " 'abs',\n",
       " 'agg',\n",
       " 'all',\n",
       " 'allele_type',\n",
       " 'any',\n",
       " 'approx_equal',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'array',\n",
       " 'array_scan',\n",
       " 'asc',\n",
       " 'backend',\n",
       " 'balding_nichols_model',\n",
       " 'binary_search',\n",
       " 'bind',\n",
       " 'binom_test',\n",
       " 'bit_and',\n",
       " 'bit_lshift',\n",
       " 'bit_not',\n",
       " 'bit_or',\n",
       " 'bit_rshift',\n",
       " 'bit_xor',\n",
       " 'bool',\n",
       " 'builders',\n",
       " 'call',\n",
       " 'case',\n",
       " 'ceil',\n",
       " 'chi_squared_test',\n",
       " 'citation',\n",
       " 'cite_hail',\n",
       " 'cite_hail_bibtex',\n",
       " 'coalesce',\n",
       " 'concordance',\n",
       " 'cond',\n",
       " 'context',\n",
       " 'contig_length',\n",
       " 'contingency_table_test',\n",
       " 'copy_log',\n",
       " 'corr',\n",
       " 'cumulative_sum',\n",
       " 'current_backend',\n",
       " 'dbeta',\n",
       " 'de_novo',\n",
       " 'debug_info',\n",
       " 'default_reference',\n",
       " 'delimit',\n",
       " 'desc',\n",
       " 'dict',\n",
       " 'downcode',\n",
       " 'dpois',\n",
       " 'dtype',\n",
       " 'empty_array',\n",
       " 'empty_dict',\n",
       " 'empty_set',\n",
       " 'entropy',\n",
       " 'eval',\n",
       " 'eval_timed',\n",
       " 'eval_typed',\n",
       " 'exp',\n",
       " 'experimental',\n",
       " 'export_bgen',\n",
       " 'export_elasticsearch',\n",
       " 'export_gen',\n",
       " 'export_plink',\n",
       " 'export_vcf',\n",
       " 'expr',\n",
       " 'filter',\n",
       " 'filter_alleles',\n",
       " 'filter_alleles_hts',\n",
       " 'filter_intervals',\n",
       " 'find',\n",
       " 'fisher_exact_test',\n",
       " 'flatmap',\n",
       " 'flatten',\n",
       " 'float',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'floor',\n",
       " 'fold',\n",
       " 'format',\n",
       " 'genetic_relatedness_matrix',\n",
       " 'genetics',\n",
       " 'get_reference',\n",
       " 'get_sequence',\n",
       " 'get_vcf_metadata',\n",
       " 'gp_dosage',\n",
       " 'gq_from_pl',\n",
       " 'grep',\n",
       " 'group_by',\n",
       " 'hadoop_copy',\n",
       " 'hadoop_exists',\n",
       " 'hadoop_is_dir',\n",
       " 'hadoop_is_file',\n",
       " 'hadoop_ls',\n",
       " 'hadoop_open',\n",
       " 'hadoop_stat',\n",
       " 'hamming',\n",
       " 'hardy_weinberg_test',\n",
       " 'hts_entry_schema',\n",
       " 'hwe_normalized_pca',\n",
       " 'identity_by_descent',\n",
       " 'if_else',\n",
       " 'import_bed',\n",
       " 'import_bgen',\n",
       " 'import_fam',\n",
       " 'import_gen',\n",
       " 'import_gvcfs',\n",
       " 'import_locus_intervals',\n",
       " 'import_matrix_table',\n",
       " 'import_plink',\n",
       " 'import_table',\n",
       " 'import_vcf',\n",
       " 'import_vcfs',\n",
       " 'impute_sex',\n",
       " 'index_bgen',\n",
       " 'init',\n",
       " 'int',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'interval',\n",
       " 'ir',\n",
       " 'is_complex',\n",
       " 'is_defined',\n",
       " 'is_deletion',\n",
       " 'is_finite',\n",
       " 'is_indel',\n",
       " 'is_infinite',\n",
       " 'is_insertion',\n",
       " 'is_missing',\n",
       " 'is_mnp',\n",
       " 'is_nan',\n",
       " 'is_snp',\n",
       " 'is_star',\n",
       " 'is_strand_ambiguous',\n",
       " 'is_transition',\n",
       " 'is_transversion',\n",
       " 'is_valid_contig',\n",
       " 'is_valid_locus',\n",
       " 'json',\n",
       " 'lambda_gc',\n",
       " 'ld_matrix',\n",
       " 'ld_prune',\n",
       " 'len',\n",
       " 'liftover',\n",
       " 'linalg',\n",
       " 'linear_mixed_model',\n",
       " 'linear_mixed_regression_rows',\n",
       " 'linear_regression_rows',\n",
       " 'literal',\n",
       " 'locus',\n",
       " 'locus_from_global_position',\n",
       " 'locus_interval',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'logistic_regression_rows',\n",
       " 'map',\n",
       " 'matrixtable',\n",
       " 'max',\n",
       " 'maximal_independent_set',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'mendel_error_code',\n",
       " 'mendel_errors',\n",
       " 'methods',\n",
       " 'min',\n",
       " 'min_rep',\n",
       " 'nanmax',\n",
       " 'nanmin',\n",
       " 'nd',\n",
       " 'nirvana',\n",
       " 'null',\n",
       " 'or_else',\n",
       " 'or_missing',\n",
       " 'pF',\n",
       " 'pT',\n",
       " 'parse_call',\n",
       " 'parse_float',\n",
       " 'parse_float32',\n",
       " 'parse_float64',\n",
       " 'parse_int',\n",
       " 'parse_int32',\n",
       " 'parse_int64',\n",
       " 'parse_locus',\n",
       " 'parse_locus_interval',\n",
       " 'parse_variant',\n",
       " 'pc_relate',\n",
       " 'pca',\n",
       " 'pchisqtail',\n",
       " 'pl_dosage',\n",
       " 'pl_to_gp',\n",
       " 'plot',\n",
       " 'pnorm',\n",
       " 'poisson_regression_rows',\n",
       " 'ppois',\n",
       " 'product',\n",
       " 'qchisqtail',\n",
       " 'qnorm',\n",
       " 'qpois',\n",
       " 'rand_beta',\n",
       " 'rand_bool',\n",
       " 'rand_cat',\n",
       " 'rand_dirichlet',\n",
       " 'rand_gamma',\n",
       " 'rand_norm',\n",
       " 'rand_norm2d',\n",
       " 'rand_pois',\n",
       " 'rand_unif',\n",
       " 'range',\n",
       " 'rbind',\n",
       " 'read_matrix_table',\n",
       " 'read_table',\n",
       " 'realized_relationship_matrix',\n",
       " 'rename_duplicates',\n",
       " 'reverse_complement',\n",
       " 'reversed',\n",
       " 'row_correlation',\n",
       " 'sample_qc',\n",
       " 'scan',\n",
       " 'set',\n",
       " 'set_global_seed',\n",
       " 'sign',\n",
       " 'skat',\n",
       " 'sorted',\n",
       " 'spark_context',\n",
       " 'split_multi',\n",
       " 'split_multi_hts',\n",
       " 'sqrt',\n",
       " 'stats',\n",
       " 'stop',\n",
       " 'str',\n",
       " 'struct',\n",
       " 'sum',\n",
       " 'summarize_variants',\n",
       " 'switch',\n",
       " 'table',\n",
       " 'tarray',\n",
       " 'tblockmatrix',\n",
       " 'tbool',\n",
       " 'tcall',\n",
       " 'tdict',\n",
       " 'tfloat',\n",
       " 'tfloat32',\n",
       " 'tfloat64',\n",
       " 'tint',\n",
       " 'tint32',\n",
       " 'tint64',\n",
       " 'tinterval',\n",
       " 'tlocus',\n",
       " 'tmatrix',\n",
       " 'tndarray',\n",
       " 'transmission_disequilibrium_test',\n",
       " 'triangle',\n",
       " 'trio_matrix',\n",
       " 'tset',\n",
       " 'tstr',\n",
       " 'tstruct',\n",
       " 'ttable',\n",
       " 'ttuple',\n",
       " 'tunion',\n",
       " 'tuple',\n",
       " 'tvariable',\n",
       " 'tvoid',\n",
       " 'typecheck',\n",
       " 'uniroot',\n",
       " 'unphased_diploid_gt_index_call',\n",
       " 'utils',\n",
       " 'variant_qc',\n",
       " 'variant_str',\n",
       " 'vep',\n",
       " 'version',\n",
       " 'zip',\n",
       " 'zip_with_index']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://hail.is/docs/0.2/getting_started.html\n",
    "# Python 3.6 or 3.7. We recommend Miniconda Python 3.7 Hail does not support Python 3.8.\n",
    "\n",
    "# Java 8 JRE Note: it must be Java 8. Hail does not support versions 9+ due to our dependency on Spark.\n",
    "\n",
    "# conda install openjdk\n",
    "# conda install pyspark\n",
    "\n",
    "import hail as hl\n",
    "\n",
    "dir(hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Spark and Hail with default parameters...\n",
      "Running on Apache Spark version 2.4.1\n",
      "SparkUI available at http://192.168.1.79:4040\n",
      "Welcome to\n",
      "     __  __     <>__\n",
      "    / /_/ /__  __/ /\n",
      "   / __  / _ `/ / /\n",
      "  /_/ /_/\\_,_/_/_/   version 0.2.32-a5876a0a2853\n",
      "LOGGING: writing to /home/zeno/hail-20200209-0035-0.2.32-a5876a0a2853.log\n",
      "2020-02-09 00:35:51 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 50 samples, and 100 variants...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 50)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-09 00:45:53 Hail: INFO: downloading 1KG VCF ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/1kg.vcf.bgz\n",
      "2020-02-09 00:45:57 Hail: INFO: importing VCF and writing to matrix table...\n",
      "2020-02-09 00:46:02 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 00:46:10 Hail: INFO: wrote matrix table with 10961 rows and 284 columns in 16 partitions to data/1kg.mt\n",
      "2020-02-09 00:46:10 Hail: INFO: downloading 1KG annotations ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/1kg_annotations.txt\n",
      "2020-02-09 00:46:10 Hail: INFO: downloading Ensembl gene annotations ...\n",
      "  Source: https://storage.googleapis.com/hail-tutorial/ensembl_gene_annotations.txt\n",
      "2020-02-09 00:46:12 Hail: INFO: Done!\n",
      "2020-02-09 00:46:20 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 00:46:25 Hail: INFO: wrote matrix table with 10961 rows and 284 columns in 2 partitions to data/1kg.mt\n",
      "2020-02-09 00:49:15 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 00:49:16 Hail: INFO: Finished type imputation\n",
      "  Loading column 'Sample' as type 'str' (imputed)\n",
      "  Loading column 'Population' as type 'str' (imputed)\n",
      "  Loading column 'SuperPopulation' as type 'str' (imputed)\n",
      "  Loading column 'isFemale' as type 'bool' (imputed)\n",
      "  Loading column 'PurpleHair' as type 'bool' (imputed)\n",
      "  Loading column 'CaffeineConsumption' as type 'int32' (imputed)\n",
      "2020-02-09 00:54:43 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,\n",
      "    with input variable x, and 1 additional covariate...\n",
      "2020-02-09 00:57:39 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-02-09 00:58:11 Hail: INFO: hwe_normalized_pca: running PCA using 7841 variants.\n",
      "2020-02-09 00:58:13 Hail: INFO: pca: running PCA with 10 components...\n",
      "2020-02-09 00:59:09 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,\n",
      "    with input variable x, and 5 additional covariates...\n",
      "2020-02-09 00:59:13 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-02-09 00:59:22 Hail: WARN: entries(): Resulting entries table is sorted by '(row_key, col_key)'.\n",
      "    To preserve row-major matrix table order, first unkey columns with 'key_cols_by()'\n",
      "2020-02-09 00:59:28 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-02-09 00:59:37 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 00:59:38 Hail: INFO: Finished type imputation\n",
      "  Loading column 'Sample' as type 'str' (imputed)\n",
      "  Loading column 'Population' as type 'str' (imputed)\n",
      "  Loading column 'SuperPopulation' as type 'str' (imputed)\n",
      "  Loading column 'isFemale' as type 'bool' (imputed)\n",
      "  Loading column 'PurpleHair' as type 'bool' (imputed)\n",
      "  Loading column 'CaffeineConsumption' as type 'int32' (imputed)\n",
      "2020-02-09 00:59:39 Hail: INFO: hwe_normalized_pca: running PCA using 9169 variants.\n",
      "2020-02-09 00:59:40 Hail: INFO: pca: running PCA with 10 components...\n",
      "2020-02-09 00:59:45 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,\n",
      "    with input variable x, and 5 additional covariates...\n",
      "2020-02-09 01:01:22 Hail: INFO: downloading MovieLens-100k data ...\n",
      "  Source: http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
      "2020-02-09 01:01:25 Hail: INFO: importing users table and writing to data/users.ht ...\n",
      "2020-02-09 01:01:27 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 01:01:27 Hail: INFO: Finished type imputation\n",
      "  Loading column 'f0' as type 'int32' (imputed)\n",
      "  Loading column 'f1' as type 'int32' (imputed)\n",
      "  Loading column 'f2' as type 'str' (imputed)\n",
      "  Loading column 'f3' as type 'str' (imputed)\n",
      "  Loading column 'f4' as type 'str' (imputed)\n",
      "2020-02-09 01:01:28 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:01:29 Hail: INFO: wrote table with 943 rows in 4 partitions to data/users.ht\n",
      "2020-02-09 01:01:29 Hail: INFO: importing movies table and writing to data/movies.ht ...\n",
      "2020-02-09 01:01:29 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 01:01:29 Hail: INFO: Finished type imputation\n",
      "  Loading column 'f0' as type 'int32' (imputed)\n",
      "  Loading column 'f1' as type 'str' (imputed)\n",
      "  Loading column 'f2' as type 'str' (imputed)\n",
      "  Loading column 'f3' as type 'str' (imputed)\n",
      "  Loading column 'f4' as type 'str' (imputed)\n",
      "  Loading column 'f5' as type 'int32' (imputed)\n",
      "  Loading column 'f6' as type 'int32' (imputed)\n",
      "  Loading column 'f7' as type 'int32' (imputed)\n",
      "  Loading column 'f8' as type 'int32' (imputed)\n",
      "  Loading column 'f9' as type 'int32' (imputed)\n",
      "  Loading column 'f10' as type 'int32' (imputed)\n",
      "  Loading column 'f11' as type 'int32' (imputed)\n",
      "  Loading column 'f12' as type 'int32' (imputed)\n",
      "  Loading column 'f13' as type 'int32' (imputed)\n",
      "  Loading column 'f14' as type 'int32' (imputed)\n",
      "  Loading column 'f15' as type 'int32' (imputed)\n",
      "  Loading column 'f16' as type 'int32' (imputed)\n",
      "  Loading column 'f17' as type 'int32' (imputed)\n",
      "  Loading column 'f18' as type 'int32' (imputed)\n",
      "  Loading column 'f19' as type 'int32' (imputed)\n",
      "  Loading column 'f20' as type 'int32' (imputed)\n",
      "  Loading column 'f21' as type 'int32' (imputed)\n",
      "  Loading column 'f22' as type 'int32' (imputed)\n",
      "  Loading column 'f23' as type 'int32' (imputed)\n",
      "2020-02-09 01:01:30 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:01:32 Hail: INFO: wrote table with 1682 rows in 4 partitions to data/movies.ht\n",
      "2020-02-09 01:01:32 Hail: INFO: importing ratings table and writing to data/ratings.ht ...\n",
      "2020-02-09 01:01:32 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 01:01:32 Hail: INFO: Finished type imputation\n",
      "  Loading column 'f0' as type 'int32' (imputed)\n",
      "  Loading column 'f1' as type 'int32' (imputed)\n",
      "  Loading column 'f2' as type 'int32' (imputed)\n",
      "  Loading column 'f3' as type 'int32' (imputed)\n",
      "2020-02-09 01:01:33 Hail: INFO: wrote table with 100000 rows in 4 partitions to data/ratings.ht\n",
      "2020-02-09 01:02:32 Hail: INFO: Movie Lens files found!\n",
      "2020-02-09 01:05:34 Hail: INFO: 1KG files found\n",
      "2020-02-09 01:05:39 Hail: INFO: Reading table to impute column types\n",
      "2020-02-09 01:05:41 Hail: INFO: Finished type imputation\n",
      "  Loading column 'Sample' as type 'str' (imputed)\n",
      "  Loading column 'Population' as type 'str' (imputed)\n",
      "  Loading column 'SuperPopulation' as type 'str' (imputed)\n",
      "  Loading column 'isFemale' as type 'bool' (imputed)\n",
      "  Loading column 'PurpleHair' as type 'bool' (imputed)\n",
      "  Loading column 'CaffeineConsumption' as type 'int32' (imputed)\n",
      "2020-02-09 01:06:12 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,\n",
      "    with input variable x, and 1 additional covariate...\n",
      "2020-02-09 01:06:27 Hail: INFO: hwe_normalized_pca: running PCA using 9169 variants.\n",
      "2020-02-09 01:06:29 Hail: INFO: pca: running PCA with 10 components...\n",
      "2020-02-09 01:06:37 Hail: WARN: cols(): Resulting column table is sorted by 'col_key'.\n",
      "    To preserve matrix table column order, first unkey columns with 'key_cols_by()'\n",
      "2020-02-09 01:06:38 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:06:38 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:06:39 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:06:39 Hail: INFO: Coerced sorted dataset\n",
      "2020-02-09 01:06:42 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-02-09 01:06:52 Hail: INFO: Ordering unsorted dataset with network shuffle\n",
      "2020-02-09 01:06:56 Hail: INFO: Ordering unsorted dataset with network shuffle\n"
     ]
    }
   ],
   "source": [
    "mt = hl.balding_nichols_model(n_populations=3, n_samples=50, n_variants=100)\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GATK4\n",
    "# git-lfs 1.1.0 or greater. \n",
    "# Required to download the large files used to build GATK, and test files required\n",
    "# to run the test suite. Run git lfs install after downloading, \n",
    "# followed by git lfs pull from the root of your git clone to download all of the large files,\n",
    "# including those required to run the test suite.\n",
    "# The full download is approximately 2 gigabytes.\n",
    "\n",
    "# sudo apt install git-lfs\n",
    "\n",
    "# git clone https://github.com/broadinstitute/gatk.git\n",
    "\n",
    "# If running from a cloned repository, run ./gradlew localDevCondaEnv.\n",
    "# This generates the Python package archive and conda yml dependency file(s)\n",
    "# in the build directory, and also creates (or updates) the local gatk conda environment.\n",
    "\n",
    "# time ./gradlew localDevCondaEnv\n",
    "\n",
    "# Build the GATK:\n",
    "# full build\n",
    "# ./gradlew bundle (creates gatk-VERSION.zip in build/)\n",
    "\n",
    "# test by:\n",
    "# ./gradlew test\n",
    "\n",
    "# Get help on running the GATK: ./gatk --help\n",
    "# Get a list of available tools: ./gatk --list\n",
    "# Run a tool: ./gatk PrintReads -I src/test/resources/NA12878.chr17_69k_70k.dictFix.bam -O output.bam\n",
    "# Get help on a particular tool: ./gatk PrintReads --help"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
